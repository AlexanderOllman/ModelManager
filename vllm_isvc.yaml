#correct formatting
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: vllm-facebook-opt-125m
  annotations:
    autoscaling.knative.dev/target: "1"
    autoscaling.knative.dev/class: "kpa.autoscaling.knative.dev"
    autoscaling.knative.dev/minScale: "1"
    autoscaling.knative.dev/maxScale: "1"
    serving.knative.dev/scale-to-zero-grace-period: "infinite"
    serving.kserve.io/enable-auth: "false"
    serving.knative.dev/scaleToZeroPodRetention: "false"
spec:
  predictor:
    containers:
      - name: kserve-container
        args:
          - "--port"
          - "8080"  # Changed to 8080 to match KServe's expected port
          - "--model"
          - "facebook/opt-125m"
        command:
          - "python3"
          - "-m"
          - "vllm.entrypoints.api_server"
        env:
          - name: "HF_HOME"
            value: "/mnt/models-pvc"   
          - name: "HF_HUB_CACHE"
            value: "/mnt/models-pvc/hub"     
          - name: "XDG_CACHE_HOME"
            value: "/mnt/models-pvc/.cache"    
          - name: "XDG_CONFIG_HOME"
            value: "/mnt/models-pvc/.config"
          - name: "PROTOCOL"
            value: "v2"
          - name: "SCALE_TO_ZERO_ENABLED"
            value: "false"
        image: vllm/vllm-openai:latest
        imagePullPolicy: IfNotPresent
        ports:
          - containerPort: 8080  # Explicitly define the container port
            protocol: TCP
        readinessProbe: #Perform check to see if the endpoint is ready after deployment.
          httpGet:
            path: /health
            port: 8080  # Updated port
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 8080  # Updated port
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
        resources:
          limits:
            cpu: "4"
            memory: "16Gi"
            nvidia.com/gpu: "1"
          requests:
            cpu: "2"
            memory: "8Gi"
            nvidia.com/gpu: "1"
        volumeMounts:
          - name: model-pvc
            mountPath: /mnt/models-pvc
    volumes:
      - name: model-pvc
        persistentVolumeClaim:
          claimName: models-pvc